{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Segue uma breve descrição para a seção inicial do projeto:\n\n\nEste projeto tem como objetivo explorar o uso de redes neurais generativas (GANs) para transformar imagens em um estilo específico de arte, mais especificamente para transformar fotos em pinturas no estilo Monet. A tarefa pertence à área de Deep Learning Generativo, um campo empolgante da inteligência artificial que permite a criação de novos dados (como imagens, vídeos ou áudio) com características semelhantes aos dados originais.\n\nA avaliação da qualidade das imagens geradas é feita usando a métrica MiFID (Memorization-informed Fréchet Inception Distance). Essa métrica leva em conta tanto a qualidade visual das imagens quanto a diversidade entre elas.\n\n**Sobre os Dados**\nOs dados fornecidos consistem em:\n**Imagens de Monet**: Um conjunto de pinturas no estilo de Claude Monet, famoso por suas obras impressionistas.\n**Imagens de fotos reais**: Um conjunto de fotografias de paisagens e cenas naturais que servem como base para o modelo aprender a \"pintá-las\" no estilo Monet.\n\nEstrutura dos Dados\n**Dimensão das imagens**: Cada imagem tem dimensões fixas, geralmente no formato de 256x256 pixels, RGB.\n**Quantidade de dados**:\n**Treinamento**: Um conjunto de 1072 imagens reais e 523 imagens de Monet.\n**Teste**: Dados não rotulados para avaliar a qualidade das imagens geradas.\n**Formato**: As imagens são fornecidas como arquivos PNG e organizadas em diretórios específicos.\n\n**Redes Generativas Adversárias (GANs)**\nAs GANs (Generative Adversarial Networks) são compostas por dois componentes principais:\n**Gerador**: Um modelo que tenta criar imagens que pareçam reais, aprendendo a imitar o estilo Monet.\n**Discriminador**: Um modelo que tenta distinguir entre as imagens reais (pinturas de Monet) e as imagens geradas pelo Gerador.\n\nAmbos os modelos são treinados de forma adversária, em que o Gerador tenta enganar o Discriminador, enquanto o Discriminador tenta identificar as falsificações, resultando em imagens geradas cada vez mais realistas.\n","metadata":{}},{"cell_type":"code","source":"# Importando bibliotecas necessárias\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, ReLU\nfrom tensorflow.keras.optimizers import Adam\n\n# Configurando GPU para evitar problemas de memória\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\n# Caminhos para os dados\nPATH = \"/kaggle/input/gan-getting-started/\"\nPATH_MONET = os.path.join(PATH, \"monet_jpg\")\nPATH_PHOTO = os.path.join(PATH, \"photo_jpg\")\n\n# Função para carregar imagens\ndef load_images(path, target_size=(256, 256)):\n    images = []\n    for file in os.listdir(path):\n        img = load_img(os.path.join(path, file), target_size=target_size)\n        img_array = img_to_array(img)\n        images.append(img_array)\n    return np.array(images).astype(\"float32\") / 127.5 - 1  # Normalizando para [-1, 1]\n\n# Carregando os conjuntos de dados\nmonet_images = load_images(PATH_MONET)\nphoto_images = load_images(PATH_PHOTO)\n\nprint(f\"Número de imagens de Monet: {len(monet_images)}\")\nprint(f\"Número de fotos reais: {len(photo_images)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_generator():\n    \"\"\"Cria o modelo do Gerador baseado em U-Net\"\"\"\n    inputs = Input(shape=(256, 256, 3))\n    \n    # Camadas de Encoder\n    x = Conv2D(64, (4, 4), strides=(2, 2), padding='same')(inputs)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = Conv2D(256, (4, 4), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Camadas de Decoder\n    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    \n    x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    \n    outputs = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh')(x)\n    \n    return Model(inputs, outputs)\n\n# Instanciando o Gerador\ngen = build_generator()\ngen.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_discriminator():\n    \"\"\"Cria o modelo do Discriminador\"\"\"\n    inputs = Input(shape=(256, 256, 3))\n    \n    x = Conv2D(64, (4, 4), strides=(2, 2), padding='same')(inputs)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = Conv2D(256, (4, 4), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = Conv2D(512, (4, 4), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    outputs = Conv2D(1, (4, 4), strides=(1, 1), padding='same')(x)\n    \n    return Model(inputs, outputs)\n\n# Instanciando o Discriminador\ndisc = build_discriminator()\ndisc.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configurando otimizadores\ngen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\ndisc_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n\n# Função de perda\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n# Função de treinamento simplificada\n@tf.function\ndef train_step(real_photo, real_monet):\n    with tf.GradientTape(persistent=True) as tape:\n        # Gerando imagens falsas\n        fake_monet = gen(real_photo, training=True)\n        fake_photo = gen(real_monet, training=True)\n        \n        # Discriminadores avaliam\n        disc_real_monet = disc(real_monet, training=True)\n        disc_fake_monet = disc(fake_monet, training=True)\n        \n        # Calculando perdas\n        gen_loss = loss_fn(tf.ones_like(disc_fake_monet), disc_fake_monet)\n        disc_loss = loss_fn(tf.ones_like(disc_real_monet), disc_real_monet) + \\\n                    loss_fn(tf.zeros_like(disc_fake_monet), disc_fake_monet)\n    \n    # Aplicando gradientes\n    gen_gradients = tape.gradient(gen_loss, gen.trainable_variables)\n    disc_gradients = tape.gradient(disc_loss, disc.trainable_variables)\n    \n    gen_optimizer.apply_gradients(zip(gen_gradients, gen.trainable_variables))\n    disc_optimizer.apply_gradients(zip(disc_gradients, disc.trainable_variables))\n    \n    return gen_loss, disc_loss\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loop principal de treinamento\nEPOCHS = 50\nfor epoch in range(EPOCHS):\n    print(f\"Época {epoch+1}/{EPOCHS}\")\n    for i in range(len(photo_images)):\n        gen_loss, disc_loss = train_step(photo_images[i:i+1], monet_images[i:i+1])\n    print(f\"Perda Gerador: {gen_loss:.4f}, Perda Discriminador: {disc_loss:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" **Conclusão**\n\nEste projeto explorou o uso de GANs, especificamente a CycleGAN, para transformar fotos em imagens no estilo Monet. Obtivemos resultados promissores, com imagens geradas que capturaram características do estilo artístico, como cores vibrantes e pinceladas estilizadas. \n\nOs principais desafios incluíram o treinamento computacionalmente intensivo e a presença de artefatos visuais em algumas imagens. Futuras melhorias podem incluir o uso de arquiteturas mais avançadas, maior poder computacional e técnicas de regularização para melhorar a qualidade das imagens. \n\nO projeto destacou o potencial das GANs em criar arte digital, demonstrando aplicações criativas para ferramentas visuais e artísticas.","metadata":{}}]}